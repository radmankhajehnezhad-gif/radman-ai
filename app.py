import gradio as gr
from transformers import pipeline
import os
import json

memory_file = "memory.json"
if os.path.exists(memory_file):
    with open(memory_file, "r", encoding="utf-8") as f:
        memory = json.load(f)
else:
    memory = {}

generator = pipeline("text2text-generation", model="google/flan-t5-small")

def radman_ai(user_input):
    answer = generator(user_input, max_length=100)[0]['generated_text']
    memory[user_input] = answer
    with open(memory_file, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=4)
    return answer

with gr.Blocks() as demo:
    gr.Markdown("""# ðŸ¤– Ø±Ø§Ø¯Ù…Ø§Ù† AI ÙˆØ§Ù‚Ø¹ÛŒ
Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù¾Ø±Ø³ Ùˆ Ø¬ÙˆØ§Ø¨ Ø·Ø¨ÛŒØ¹ÛŒ Ø¨Ú¯ÛŒØ±.""")
    with gr.Row():
        user_input = gr.Textbox(label="Ù¾ÛŒØ§Ù… Ø´Ù…Ø§", placeholder="Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯...")
        submit_btn = gr.Button("Ø§Ø±Ø³Ø§Ù„")
    output = gr.Textbox(label="Ù¾Ø§Ø³Ø® Ø±Ø§Ø¯Ù…Ø§Ù†")
    submit_btn.click(fn=radman_ai, inputs=user_input, outputs=output)

demo.launch(server_name="0.0.0.0", server_port=int(os.environ.get("PORT", 8080)), share=False)
